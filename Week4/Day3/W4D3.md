# Introduction to IaaS/SaaS/PaaS

SAAS - Software as a Service - This offers a complete application for the user

-   Example: Google docs, zoom

PAAS Platform as a service - The cloud delivers the hardware and software tools for the purpose of application development

-   Example: AWS RDS, GCP Cloud SQL (Relationship Database Service)

IAAS - Infrastructure as a service - The cloud provider hosts the hardware and very basic software (like an Operating System) for the client to design their own environment and applications.

-   Example: AWS EC2, GPC Compute Engine

# Containers vs VMs

Containers and Virtual Machines both provide the ability to isolate processes, however each have their own pros and cons

## Virtual Machines: simulate a physical server/machine

-   They virtualize an entire OS
-   Enabled by hypervisors, a software that coordinates between multiple VM's and interfaces with the underlying infastructure

VM Pros:

-   near total isolation
-   provides virtualization
-   ensures an application runs reliably regardles of the host

VM Cons:

-   considered bulky, expensize in context of resources

## Containers: bundle together applications with their supporting libraries and dependencies allowing them to run in isolation

-   The container will share the underlying OS kernel
-   Much lighter weight than a VM
-   Containerization is provided by an engine running on the host, ie Docker

Container Pros:

-   considered lightweight, because they don't require spinning a whole OS
-   they can enable layers of isolation
-   provide a virtualized view of certain resources
-   package an application in an isolated environment
-   ensure an application runs reliably regardless of the host

Container Cons:

-   having of layers of isolation can make things difficult

In general, it is suggested to use containers over VM's becuase of the cost of resources

# Containerization

Helps to ensure the application, or set of processes can run reliably regardless of the host environment. The container shouldn't be able to modify or interact with anything it doesn't need to and on the whole, changes in the container should not effect the host or other containers

Linux Containers are the foundation of most modern container systems

-   began with cgroups and namespaces
    -   cgroups allowed controll over the resources
    -   namespaces allowed for encapsulation of resources, and determined what is visible to particular processes

These containers are:

-   built from images ( a template for the container)
-   run on an engine (on the host OS) ie Docker Engine
-   Are ideally stateless
    -   any state that is needed for the application should be stored in a way that is detachable from the actual container
-   Virtualized and isolated

More benefits of containers:

-   Secure
-   Standardized and portable
-   LightWeight
-   Flexible and loosely coupled
-   Scalable

# Intro to Docker

Docker is an open source platform for developing, shipping, and running applications using containers

# Docker Architecture

Docker runs on a Client-Server Architecure

-   You run commands on the Client, which interacts with the Docker Daemon

![docker-arch](docker.svg)

## Docker CLI

The Docker Command Line Interface is the client in the client-server architecture

-   It is used to interact with the Daemon
-   Uses a Rest API to send command to the Docker Daemon

## Docker Daemon

The Docker Daemon is the long running process on the docker host that does all of the heavy lifting

-   manage Docker objects
-   containers
-   images
-   the core of the running dockerized applications

## DockerHub Container Registry

Provides a centralized place to store images, allowing you to easily share images between docker hosts.

-   Dockerhub is a public registry managed by docker, that allows you to push and pull containers

# Docker Objects

Are the building blocks that are managed by the docker daemon. The most fundamental objects are images and containers

## Docker Images

Docker Imagers are a blueprint for a container

-   Outlined in a dockerfile

## Docker Containers

Docker container are a runnable isolation instance of a set of processes and their dependencies

-   These are built from docker images, which lays out everything the processes that run in the container will need
-   managed by the docker daemon as part of the docker engine

# Dockerfile

Define everything needed for an image. It outlines the starting point, dependencies, and commands that make up all the processes for an image and in turn a container

-   Use these to create our images, contains a step-by-step instructions to create the image

# Dockerfile Keywords

`FROM image name`

-   Specifies the parent image from which the new image should be based

`RUN <command> / RUN ["executable", "param"]`

-   used to setup your image, the state of the image after each run command is commited forms a new layer

`ADD <src> <dest>`

-   adds files from build context or url to image

`COPY <src> <dest>`

-   adds files from build context to image, now perfered over ADD

`EXPOSE`

-   outline ports that being listened on by processes in the container

`VOLUME [/dirname]`

-   create a mount point in the image, and thus container with a particular

`WORKDIR`

-   set the working directory in the image and the eventual cointainer of commands that follow

`CMD`

-   used to execute/run processes needed inside of your container

# Building an Image

There are two ways to create an image:

-   Using the `docker build anyflags PATH` command in the CLI
    -   This is how you can create an image with a dockerfile
-   Using `docker commit flags CONTAINER imagename` command in the CLI
    -   You are commiting the changes from the container specified to the image specified
    -   You are creating an image based off of an existing docker container

# Creating a container

There are two ways to create a Docker container

-   Using `docker create imagename` in the CLI
    -   this creates a container in its created state, and configures and sets it up to be run, including the writible layer on the image from which the container is created
-   Using `docker run flags imagename` in the CLI
    -   This will pull the image from the registry if it doesn't exist locally
    -   Create and run the container automatically

# Managing Containers:

Some useful commands to manage containers include:

-   `docker container ls` displays all running containers
-   `docker ps -a` display all containers
-   `docker container kill containerID` can be used to stop a container
-   `docker container pause containerID` can pause the processes in the container
-   `docker container start containerID` can start the processes in the container
-   `docker container rm flags containerID` will remove a container
-   `docker volume rm volumename` will remove a volume

There are more commands in this cheatsheet: https://www.docker.com/sites/default/files/d8/2019-09/docker-cheat-sheet.pdf

# Docker Networking

One of the reasons Docker containers and services are so powerful is that you can connect them together, or connect them to non-Docker workloads. Docker containers and services do not even need to be aware that they are deployed on Docker, or whether their peers are also Docker workloads or not. Whether your Docker hosts run Linux, Windows, or a mix of the two, you can use Docker to manage them in a platform-agnostic way.

By default, Docker provides two network drivers for you, the `bridge` and the `overlay` drivers. You can also write a network driver plugin so that you can create your own drivers but that is an advanced task.

To add a container to a network use the command `docker run -d --net=bridge --name nameofcontainer`

# Docker Best Practices

The goals of containerization are:

-   ephemeral containers: the containers should be as easy as possible to tear down and build up requiring minimal configuration
-   lightweight containers and images

Be mindful of build context, aka what directory we are building in

Try to leverage multi-stage builds and image cache

Each container should only serve one purpose

Make commands in dockerfiles readible by separating them on different lines

Use volumes to persist data

Use secrets for sensitive data and config files for configurations that are not sensitive


# Docker Example

1. Setup the build.gradle

```
/*
 * This file was generated by the Gradle 'init' task.
 *
 * This generated file contains a sample Java application project to get you started.
 * For more details take a look at the 'Building Java & JVM projects' chapter in the Gradle
 * User Manual available at https://docs.gradle.org/7.3.1/userguide/building_java_projects.html
 */

plugins {
    // Apply the application plugin to add support for building a CLI application in Java.
    id 'java'
    id 'application'
}

repositories {
    // Use Maven Central for resolving dependencies.
    mavenCentral()
}

dependencies {
    // Use JUnit test framework.
    testImplementation 'junit:junit:4.13.2'

    // https://mvnrepository.com/artifact/org.mockito/mockito-core
    testImplementation 'org.mockito:mockito-core:4.2.0'

    // This dependency is used by the application.
    implementation 'com.google.guava:guava:30.1.1-jre'

    // https://mvnrepository.com/artifact/log4j/log4j
    implementation 'log4j:log4j:1.2.17'

    // https://mvnrepository.com/artifact/org.postgresql/postgresql
    implementation 'org.postgresql:postgresql:42.3.1'

    // https://mvnrepository.com/artifact/io.javalin/javalin
    implementation 'io.javalin:javalin:4.1.1'

    // https://mvnrepository.com/artifact/org.slf4j/slf4j-simple
    implementation 'org.slf4j:slf4j-simple:1.7.32'

    // https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-databind
    implementation 'com.fasterxml.jackson.core:jackson-databind:2.13.1'

}

jar {

    duplicatesStrategy = 'include'

    from {
        configurations.runtimeClasspath.collect { it.isDirectory() ? it : zipTree(it) }
    }
    manifest {
        attributes "Main-Class": "com.example.JavalinDriver"
    }
}
```
(This one acted funny, you may have to try either way)
1a. Git Bash into the root directory of the project and run `./gradlew jar` to bundle the project into a jar

1b. Git Bash into the root directory of the project and run `gradle build` to bundle the project into a jar

2. Create the Dockerfile in the root of the project

```
FROM openjdk:8-jdk-alpine
COPY app/build/libs/app-all.jar demo.jar
CMD ["java","-jar", "/demo.jar"]`
```

-   `FROM` is typically the first instruction and sets the base image. Images can be built on top of other pre-made images, images can be found on dockerhub.
-   `RUN` is executed as the docker image is being built. Multiple RUN statements can be used (unlike CMD where only the final CMD layer will execute). In this case the RUN statement is used to remove any files in the webapps folder before adding our file.
-   `COPY` will copy images from the host machine to the container's file system. In this case the war file is being added to the tomcat webapps folder so that tomcat will automcatilly run it, and being rename from 'sample.war' to 'demo.war'.
-   `CMD` will specify the runtime arguments to be executed. In this case it will execute a script to get tomcat up and running.

3. `docker build -t sms .`

4. `docker run -d -p 7000:7000 -e DB_URL=34.121.69.220 -e DB_USERNAME=rootuser -e DB_PASSWORD=password sms`

-   -d will run the container in detached mode, aka in the background
-   -p allows us to map the container port to the host port.
-   -e sets the enviornment variables that we need to access the database

5. To verify the container is running we can use `docker ps`

6. To stop the container we can use `docker container stop name or id`

7. If you want to restart you container you can use `docker container start name or id`
