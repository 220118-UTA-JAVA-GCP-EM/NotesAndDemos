# In-depth with Git flow

Git Flow is a command line tool that can be used with get used for applications that need a more complex work flow. Git Flow is a workflow designed that was first published and made popular by Vincent Driessen and nvie. It is a robust framework for managing larger projects by defining a strict branching model designed around project release

To get started with Git Flow you simply run git flow init in your gitbash on windows, or brew install git-flow on mac os

It will walk you through setting up each of the branches to be used with the workflow, these include the main branch, or the production code branch, the development or next release branch, the feature branch, the hotfix branch, and any other support branch you might want

The git flow sets up these strict branches for you to follow the workflow of git flow

The main branch should hold the current production build of your application

The development branch holds the code that will be merged into the main branch upon next release

The feature branch is where you will develop individual features, and each of those features should individually be merged into the development branch

The hotfix branch is for any emergency fixes that need to be merged directly into the main branch upon any issues popping up during a deployment

It is best practice to not automatically merge your code into a new branch, rather you should create a pull request, which essentially tells your leader/project manager that your code is ready to be merged. Typically after a pull request is created, someone will review the code to ensure the quality is up to standards, then merge the code into the requested branch.

To create a pull request go to the repository on GitHub > Choose the Pull Requests Tab > Click on the green New pull request button

Clicking on the green button will walk you through creating a new pull request, then you can submit it

Sometimes Multiple people work on the same code, with out doing a git pull first, then they commit the changes to the same piece of code. This typically results in a merge conflict. There are two ways to deal with these. Sometimes the GitHub web interface will allow you to look at the conflicting files and keep what you want. But, other times you will need to refresh the conflicting files in your editor of choice, and you will see the conflict, pick the code change you want to keep, then commit the changes to complete the merge.

# Unix Fundamentals

Unix is an open source family of operating systems that was developed in AT&T's Bell lab in the early 1970's,

Originally a small terminal based OS with hierarchical file system, computer processes, and device files, the Unix family is now a giant tree of hundreds of OS's including Mac OS, and Linux

The original Unix used a shell called sh, in 1989 a new shell system was created for Unix called the Bourne Again Shell aka bash, and this is the terminal that all modern Unix based systems is built upon

## Linux

Linux is probably the most well known Unix based operating system outside of MacOS

Linux was created by Linus Torvalds, with support and constant updates from the open source community

Now there are many distrubitions of Linux, popular ones include Ubuntu, RedHat, Arch and more

-   Ubuntu is a great first time Linux distrobution, which is easy to understand and pick up for beginners
-   RedHat is an enterprise distribution that is NOT open source, it has great resources and is used by many companies using linux development environments
-   Arch is a highly customizable distribution that advanced Linux users can leverage to get the EXACT computing experience that they are looking for

# Linux Commands

To understand Linux commands you must first understand the file structure of the linux OS, Linux uses a tree like file system with the `root` directory of the system mapping to the `/` character

The `home` directory where user specific information is stored is denoted by the `~`

Another important note with the unix file structure is that everything in Unix is considered a file, even directories. This knowledge will come in handy later on

## Command Arguments and Flags

Commands can be modified with either arguments or flags

Arguments are given to a command after the command in the form of a string eg `command arg1 arg2...` Arugments are typically variables that your command is expecting to use during execution

Flags are denoted by either a `-` followed by a letter, which is the shorthand, or a `--` and the flag name which is the long hand, flags are special built in arguments for the command. Flags are options you can enable for your command

## Unix Navigation and Directory Commands

### Most important command `man`

The manual command will print to the terminal the manual for using a particular command. If you are unsure what flags or arguments a command takes, you simply type `man command`. For example, if you wished to see the manual for the copy command, you would issue the command: `man cp`

### Change Directory `cd`

The change directory command allows us to navigate to a different directory on the drive.

-   go to root directory: `cd /`
-   go to home directory: `cd` or `cd ~`
-   navigate one directory up: `cd ..`
-   navigate into the `hi` directory, which is inside the `bye` directory: `cd ./bye/hi`
-   change to the previous directory: `cd -`

### Listing Files in a directory `ls`

The list directory command allows us to see the contents of a particular directory. When given no arguments, it lists the contents of the 8 current directory.

-   `-a` flag allows you to see hidden items in the directory.
-   list the contents of the current directory: `ls`
-   list the contents of the `hi` directory: `ls hi` or `ls ./hi`

### Make a new directory `mkdir`

The make directory command allows us to create a new directory. mkdir takes an argument representing the name of the directory you wish to create. `mkdir supercooldirectory`

### Print the current directory `pwd`

The print working directory command prints the full name of the directory you are currently working in.

## General Purpose

### Supstitute User `su` and Super User Do`sudo`

The substitute user command allows you to switch users. With no argument, this defaults to the root user, which has higher priveleges. This can be useful if you need to perform multiple commands with elevated priveleges but is generally considered to be bad practice in preference to `sudo`, for administrative logging purposes.

The `sudo` command allows you to run a particular command as the root user.

### Clear the command line with `clear`

### Print a string to the command line with `echo string`

### Redirect the output of a command to a file with `>`

### Redirect the outpuit of a command to a file without overriding the file with `>>`

### Match patterns in a file with `grep` input is a regular expression

## Linx File Commands

### Create a file `touch`

the touch command allows you to modify the timestamp of a file. This command is usually used to create empty files, as an empty file is created if touch is given a file name that does not exist.

### Print the contents of a file `cat`

### Print the first 10 lines `head` or the last 10 lines `tail` of a file

## Unix Moving and Deleting Files

### Copy the contents of a file to another file `cp`, or the contents of a directory `cp -r`

copy a `hello.txt` to `goodbye.txt`: `cp hello.txt goodby.txt`

copy the `hello` directory to the `goodbye` directory: `cp -r hello goodbye`

### Move a file to `mv` or move a whole directory `mv -r`

the mv command allows you to rename, or move files to different directories

rename a `hello.txt` to `goodbye.txt`: `mv hello.txt goodbye.txt`

move `hello.txt` to the `goodbye` directory: `mv hello.txt goodbye/.`

rename the `hello` directory to `goodbye`: `mv hello goodbye`

### Delete a file at a specified location `rm` delete a directory `rm -r`

Never used the command `rm -rf .` this will essentially remove your entire file system

remove `hello.txt`: `rm hello.txt`

remove the `hello` directory: `rm -r hello`

### Count the words in a file `wc`

Many flags can be used with `wc` to get different outputs, including:

-   `-c, --bytes` - prints the byte count
-   `-m, --chars` - prints the character count
-   `-l, --lines` - prints the lines
-   `-w, --words` - prints the word count (default)

### Link a file to another to create a shortcut `ln`

## File Permissions

Remember that we stated that everything in Unix is a file, including directories, this makes permissions easier

In Unix file permissions are broken up into three types, Owner, Group, and Other

Owner is the original person to create and own the file

Group is a group of users that you can set on unix systems

Other is everyone else on the system

Each permission can be a combination of read which evaluates to binary 4, write which evaluates to binary 2, or execute which evaluates to binary 1, if all are true, the combination adds up to 7, if no permissions are granted the combination adds up to 0. Each one of the three above users gets a permision between 0 and 7

### To set the permission level of a user/group use the `chmod` command

The simplest way to grant permissions is using the number notation which looks like this: `chmod 754`

-   the 7 grants the owner all permissions
-   the 5 grants the group users read and execute
-   the 4 grants everyone else on the system read only

Another way is to use the letter notation that uses letters and `+`, `-`, and `=` to set/allow permissions, the letters `u` for Owner, `g` for Group, `o` for Other, and `a` for all are also used to tell unix who to give or remove permissions from

`chmod a+rwx` gives everyone all permissions

`chmod o-w` removes write access to the owner

`chmod g=o` sets the group access to the owners access

# Environment Variables

Environment variables are values that are accessible in an entire working environment. In Unix, these values are set in the shell when it is started. For example, your home directory is an environment variable called `$HOME`. If you wish to see the value of a particular environment variable, you can use the `echo` command like so: `echo $HOME`.

To set your own environment variables, you can use the `export` command. For example, if you wanted to create an environment variable to store the password to your server, you could issue the following:

```
export SERVER_PASS=password
echo $SERVER_PASS
```

However, if you issue the above command into your console, when you close the shell and open it again, your environment will no longer be present. To keep these environment variables, you will have to place the command in one of your startup files, usually

```
~/.bashrc
```

You can also remove environment variables with the `unset` command:

```
unset SERVER_PASS
echo $SERVER_PASS
```

# Package Managers

In Unix based systems if you want to download/install programs/software you will have to use a package manager, there are many pacakage managers based on different distributions including

RPM: The Red Hat package manager, built for RedHat linux, but used in other Distros, manages .rpm packages

APT: Advanced Package Tool is a package manager used on many Linux distributions, allows you to retrieve, configure, and install/uninstall software packages

YUM: Yellowdog updater modifier is a package-management utility for computers running RPM

DPKG: debian package is a low level tool that manages .deb files, it was created for debial and its derivaties

# File Editors

There are two popular choices when it comes to text/file editors for unix

vi/vim is a more advanced text editor that can be configured to your exact likings, and even turned into an IDE itself with the correct configurations. A beginners guide to Vim can be found here https://www.linux.com/training-tutorials/vim-101-beginners-guide-vim/

nano is a more beginner friendly text editor that comes with most distributions of linux, a beginners guide can be found here https://www.howtogeek.com/howto/42980/the-beginners-guide-to-nano-the-linux-command-line-text-editor/

# Intro to DevOps

DevOps is the combination of Development and Operations

And is a set of practices and methodologies designed to combine the production/writing of code and deployment/maintenance of code into one stream lined process

The primary goal of DevOps is to expedite the lifecycle of application development, particulary through the automation of tasks

This can help save money, and decrease time between releases

There is generally fives or phases to DevOps:

1. Source Code Control: Producing (writing) code and pushing to a repository
2. Building and testing automation: Test basic functionality of code, generally writing unit tests, and create a new working build
3. Deploying to staging: Deployment of working builds to a temporary environment
4. Acceptance Testing: Undergo more complex tests, (systems, integration) within the temporary environment
5. Deployment of Build: Migrate working build to the production environment access by end users

## DevOps and Agile

Adoption of the Agile process can provide a stepping stone for the establishment of a working DevOps pipeline

The processes of Continuous Integration, Continuous Delivery, and Continuous Deployment are used with agile to automate the phases of DevOps as much as possible

# Continuous Integration (CI):

CI is the process of regularly and consistently merging code into a central repository and reviewing new code to ensure that it integrates well within the previously established code base

It is the first and most fundamental step in creating an autonomous development pipeline

It is a development team mentality, and it is achieveed when all members of the development team practice consistent merging of code into a central repository, these whould be in form of version control software

Continous Integration provides the following benefits:

-   Ensures the entire team works on the most up to date code
-   Detect broken builds quickly
-   Code can be tested easily by creating separate test or development branches
-   Reduces the risk in development when a large code base had already been established
-   Reduces the overall amount of bugs in the project

# Continuous Delivery (CD):

CD allows for the building, management, and testing of produced software to be automated such that deployments can be performed at the push of a button

It is dependent upon the implementation of Continuous Integration, it can take code that is being pushed regularly, and build, test, and deploy it to a production like enviornment for final testing

The application is automatically ready for release, and can be released with the push of a button

![cd](continuous-delivery.png)

Benefits of Continuous Delivery:

-   Reduced risk in deployment
-   Predictible progress
-   Frequent feedback

# Continuous Deployment (CD):

This is the final step in completely automating your software production

It will automatically build, test, and deploy your software to the production environment, anything code is pushed to main branch

It is essentially the final addition to Continuous Delivery, it is the fully automated pipeline

Benefits of Continous Deployment:

-   Even faster development process, without the need to pause for deployment
-   New releases are less risky, as small changes can be can be easily recognized and fixed, allowing for better and quicker feedback
-   Increased communication and regular streams of improvements are generally seen as a good thing from customers

Cost/Risks of Continuous Deployment:

-   Establishing a Continous Deployment pipeline requires more substantial investment in engineering and testing culture
-   Documentation of processes is required to communicate to development, production, and testing team
-   Ongoing maintenance of deployment pipleine is required to ensure work continues running smoothly, increasing production costs
-   Feature flags are required for coordination between departments
